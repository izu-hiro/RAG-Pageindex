from os import listdir
from os.path import isfile, join
from ollama import chat
from ollama import ChatResponse
import re
import json
import pageindex.utils as utils
from docx import Document
import PyPDF2

"""rag.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/izu-hiro/RAG-Pageindex/blob/main/rag.ipynb

Definindo a LLM
"""

def getText(filename):
    doc = Document(filename)
    fullText = []
    for para in doc.paragraphs:
        fullText.append(para.text)
    return '\n'.join(fullText)

# Função retirada do próprio repositório do pageIndex
def remove_fields(data, fields=['text']):
    if isinstance(data, dict):
        return {k: remove_fields(v, fields)
            for k, v in data.items() if k not in fields}
    elif isinstance(data, list):
        return [remove_fields(item, fields) for item in data]
    return data

def call_llm(input_content, system_prompt='', deep_think = False, print_log = True):
    if system_prompt:
        response: ChatResponse = chat(model='deepseek-r1:1.5b', messages=[
            {'role': 'system', 'content': system_prompt},
            {'role': 'user', 'content': input_content}
        ])
    else:
        response: ChatResponse = chat(model='deepseek-r1:1.5b', messages=[
            {'role': 'user', 'content': input_content}
        ])
    response_text = response['message']['content']
    if print_log: print(response_text)

    think_texts = re.findall(r'<think>(.*?)</think>', response_text, flags=re.DOTALL)
    think_texts = "\n\n".join(think_texts).strip()
    clean_response = re.sub(r'<think>.*?</think>', '', response_text, flags=re.DOTALL).strip()

    return clean_response if not deep_think else (clean_response, think_texts)

#"""Carregando contexto local"""
documentos = ['documentos/'+f for f in listdir('documentos') if isfile(join('documentos', f))]
arvores = []
for documento in documentos:
    try:
        with open(documento, 'r', encoding='utf-8') as f:
            data = json.load(f)
            arvores.append(data)
    except Exception as e:
        print(f'Erro: {e}')

lei = ''
with open('L14133.pdf', 'rb') as file:
    reader = PyPDF2.PdfReader(file)
    num_pages = len(reader.pages)

    for page_num in range(num_pages):
        page = reader.pages[page_num]
        text = page.extract_text()
        lei = lei+'\n'+text

#"""Retrieval"""

def retrieval(query, tree):
    tree_without_text = remove_fields(tree.copy(), fields=['text'])

    search_prompt = f"""
    You are given a question and a tree structure of a document.
    Each node contains: node_id, node title, and a summary.
    Your task is to find all nodes that are likely to contain the answer to the question.

    Question: {query}

    Document tree structure:
    {json.dumps(tree_without_text, indent=2)}

    Please reply in the following JSON format:
    {{
        "thinking": "<Your thinking process on which nodes are relevant to the question>",
        "node_list": [ node_id, node_id, ...]
    }}
    Directly return the final JSON structure. Do not output anything else.
    """
    tree_search_result = call_llm(search_prompt)
    return tree_search_result

def multiQuery(queries, arvores):
    node_map = []
    result_json = []
    for docNum, arvore in enumerate(arvores):
        node_map.append(utils.create_node_mapping(arvore))
        result_json.append([])
        print(f"Documento {docNum}")
        for query in queries:
            if query.strip() == '':
                continue
            resposta = retrieval(query, arvore)
            tree_search_result_json = json.loads(resposta)

            print('Reasoning Process:')
            utils.print_wrapped(tree_search_result_json['thinking'])

            result_json[docNum].append(tree_search_result_json)

            print('\nRetrieved Nodes:')
            for node_id in tree_search_result_json["node_list"]:
                node = node_map[node_id]
                print(f"Node ID: {node['node_id']}\t Page: {node['page_index']}\t Title: {node['title']}")
    return node_map, result_json


print("### INICIANDO DEMONSTRAÇÃO ###\n")

# Pergunta original
original_query = """Estou te fornecendo três propostas de prestação de serviço, extraia todas as informações relevantes
 em um momento de análise de propostas e gere um estudo técnico preliminar com base nisso"""

# prompt pra llm
system_prompt_multi_query = '''
Você é um assistente especializado em reformular perguntas para recuperação de informações em documentos.
Dada uma pergunta original, gere de 3 a 5 variações semanticamente diferentes,
mantendo o mesmo significado central. Essas variações de perguntas serão utilizadas para extrair dados de
documentos a fim de responder a questão inicial gerada pelo usuário.
Gere perguntas que serão suficientes para extrair as informações necessárias de documentos que posteriormente
serão fornecidos.
Gere as reformulações separando-as com quebras de linha. Não escreva nada além das reformulações.
'''

print("--- PASSO 1: Gerando as Perguntas ---")

resposta = call_llm(original_query, system_prompt_multi_query)
multi_queries = resposta.split('\n')

print("--- PASSO 2: recuperando o contexto baseado nas perguntas ---")

node_map, tree_search_result_json = multiQuery(multi_queries, arvores)
node_lists = []
for arvore in tree_search_result_json:
    node_lists.append(arvore["node_list"])

retrieved_context = ""
for node_list in node_lists:
    retrieved_context = retrieved_context + "\n\n".join(node_map[node_id]["text"] for node_id in node_list)
    retrieved_context = retrieved_context + "\n\n"

print("Contexto recuperado com sucesso.\n")
print(f"O contexto recuperado foi:\n{retrieved_context}")

etp = getText('MODELO_DE_ESTUDO_TECNICO_PRELIMINAR_GERAL.docx')

lei = getText('MODELO_DE_ESTUDO_TECNICO_PRELIMINAR_GERAL.docx')


# prompt final
final_answer_prompt = f"""
Você é um assistente técnico especializado em análise documental para licitações,
contratações públicas e serviços administrativos.

Sua função é interpretar o conteúdo extraido dos documentos e gerar um estudo técnico preliminar de acordo com a lei das licitações

Regras:
1. Responda apenas com base nas informações do documento recuperado.
2. Se o contexto não contiver resposta suficiente, informe isso claramente.
3. Use linguagem formal e precisa, como em um parecer técnico.
4. Não invente nem adicione informações fora do contexto retornado.
5. A sua resposta deve ser apenas o resultado do estudo técnico preliminar, com seu texto 100% em português brasileiro.

### Contexto dos documentos:
{retrieved_context}

---
### Consulta do Usuário:
{original_query}
---

### Modelo de estudo técnico preliminar:
{etp}

###Lei das licitações:
{lei}

### Resposta:
"""

print("--- PASSO 3: Gerando a Resposta Final ---")

final_answer = call_llm(final_answer_prompt)
print("Resposta Gerada:\n")
print(final_answer)
    
