{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/izu-hiro/RAG-Pageindex/blob/main/prototipo_rag/quary.teste.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "id": "353e069ded4a0ab2"
  },
  {
   "metadata": {
    "id": "f8897a5bb9837baa"
   },
   "cell_type": "markdown",
   "source": "Definindo a LLM",
   "id": "c97510c1ed08c7a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8e8abf454947c53f"
  },
  {
   "metadata": {
    "collapsed": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b58922740f50bf25",
    "outputId": "ed47b3dd-fd88-4b83-afe0-37e29d83b68e",
    "ExecuteTime": {
     "end_time": "2025-10-09T22:58:40.027752Z",
     "start_time": "2025-10-09T22:58:33.946292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import AsyncOpenAI\n",
    "from getpass import getpass\n",
    "\n",
    "openrouterKey = getpass(\"Insira a sua chave API: \")\n",
    "\n",
    "async def call_llm(prompt, model=\"openai/gpt-oss-20b:free\", temperature=0):\n",
    "    client = AsyncOpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=openrouterKey)\n",
    "    response = await client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ],
   "id": "6ef9931f65af204c",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Conectando com o PageIndex",
   "id": "475a6ba64b65af82"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T22:56:07.182111Z",
     "start_time": "2025-10-09T22:54:35.950455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pageindex import PageIndexClient\n",
    "\n",
    "pi_client = PageIndexClient(api_key=getpass(\"Insira a chave API do Page Index: \"))"
   ],
   "id": "f77ba117effdf3ba",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "id": "4460f387fe7747cb"
   },
   "cell_type": "markdown",
   "source": "Contexto utilizado na geração da resposta",
   "id": "3c4f663712d97325"
  },
  {
   "metadata": {
    "id": "4348da21357ed3fb",
    "ExecuteTime": {
     "end_time": "2025-10-09T22:56:09.069783Z",
     "start_time": "2025-10-09T22:56:08.505994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pypdf import PdfWriter\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "documentos = ['documentos/'+f for f in listdir('documentos') if isfile(join('documentos', f))]\n",
    "\n",
    "merger = PdfWriter()\n",
    "for documento in documentos:\n",
    "    merger.append(documento)\n",
    "merger.write(\"documentoUnido.pdf\")\n",
    "merger.close()\n",
    "\n"
   ],
   "id": "97cc7b8d1177931f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Enviar arquivo e pegar o ID",
   "id": "38f84fabd2a1b32a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T22:56:15.729282Z",
     "start_time": "2025-10-09T22:56:11.301616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = pi_client.submit_document(\"./documentoUnido.pdf\")\n",
    "doc_id = result[\"doc_id\"]\n",
    "\n",
    "'''\n",
    "# Get OCR results in page format (default)\n",
    "ocr_result = pi_client.get_ocr(doc_id)\n",
    "if ocr_result.get(\"status\") == \"completed\":\n",
    "    print(\"OCR Results:\", ocr_result.get(\"result\"))\n",
    "'''\n",
    "\n",
    "# Get OCR results in node format\n",
    "ocr_result = pi_client.get_ocr(doc_id, format=\"node\")\n",
    "if ocr_result.get(\"status\") == \"completed\":\n",
    "    print(\"OCR Results:\", ocr_result.get(\"result\"))\n",
    "'''\n",
    "# Get OCR results in raw format (concatenated markdown)\n",
    "ocr_result = pi_client.get_ocr(doc_id, format=\"raw\")\n",
    "if ocr_result.get(\"status\") == \"completed\":\n",
    "    print(\"Raw Markdown:\", ocr_result.get(\"result\"))\n",
    "'''\n",
    "\n",
    "tree_result = pi_client.get_tree(doc_id)\n",
    "if tree_result.get(\"status\") == \"completed\":\n",
    "    print(\"PageIndex Tree Structure:\", tree_result.get(\"result\"))"
   ],
   "id": "8eade8b36786cb44",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Retrieval",
   "id": "9e9ec63eb603eedf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T22:56:18.027676Z",
     "start_time": "2025-10-09T22:56:18.020678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from time import sleep\n",
    "def retrieval(query):\n",
    "    while True:\n",
    "        if pi_client.is_retrieval_ready(doc_id):\n",
    "            retrieval = pi_client.submit_query(doc_id, query)\n",
    "            retrieval_id = retrieval['retrieval_id']\n",
    "            break\n",
    "        else:\n",
    "            print(\"Document is not ready for retrieval yet\")\n",
    "            sleep(5)\n",
    "\n",
    "    while True:\n",
    "        retrieval_result = pi_client.get_retrieval(retrieval_id)\n",
    "        if retrieval_result.get(\"status\") == \"completed\":\n",
    "            return retrieval_result.get('result')\n",
    "        sleep(1)\n"
   ],
   "id": "aecd3482fb81c425",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "id": "1970d0b0de62b5db"
   },
   "cell_type": "markdown",
   "source": "Geração da resposta",
   "id": "38b2d18e16708c4a"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c172d04976b2ed53",
    "outputId": "25e4848c-0556-4fdb-c807-2c39d27ceeee",
    "ExecuteTime": {
     "end_time": "2025-10-09T23:09:30.437040Z",
     "start_time": "2025-10-09T23:08:34.847262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"### INICIANDO DEMONSTRAÇÃO ###\\n\")\n",
    "\n",
    "# Pergunta original e específica do usuário\n",
    "original_query = \"Se eu me inscrever no último dia, 07/11/2025, e pagar a taxa com cartão de crédito, minha inscrição para o curso de Radiologia, que tem requisito de idade, será confirmada imediatamente?\"\n",
    "print(f\"Pergunta Original Específica:\\n{original_query}\\n\")\n",
    "\n",
    "\n",
    "# prompt pra llm\n",
    "\n",
    "step_back_prompt = f\"\"\"\n",
    "Dada a seguinte pergunta específica, formule uma pergunta \"step-back\" mais geral que capture os conceitos fundamentais necessários para respondê-la.\n",
    "\n",
    "Pergunta Específica: \"{original_query}\"\n",
    "\n",
    "Pergunta Step-Back Geral:\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- PASSO 1: Gerando a Pergunta ---\")\n",
    "\n",
    "step_back_question = await call_llm(step_back_prompt)\n",
    "print(f\"Pergunta Gerada: {step_back_question}\\n\")\n",
    "\n",
    "\n",
    "print(\"--- PASSO 2: Utilizando o contexto já carregado ---\")\n",
    "retrieved_context = retrieval(step_back_question)\n",
    "print(\"Contexto recuperado com sucesso.\\n\")\n",
    "print(f\"O contexto recuperado foi:\\n{retrieved_context}\")\n",
    "\n",
    "# prompt final que orienta o LLM a usar o contexto e a pergunta geral\n",
    "final_answer_prompt = f\"\"\"\n",
    "Você deve responder à \"Pergunta Específica\" usando o \"Contexto\" fornecido.\n",
    "Para te guiar, primeiro considere a \"Pergunta Step-Back Geral\" e como o contexto a responde.\n",
    "Use esse entendimento para construir uma resposta completa e precisa para a pergunta original.\n",
    "Responda somente aquilo que for passado no contexto oferecido. Se o contexto não for suficiente para responder a pergunta, apenas diga ao usuário que não foi possível responder aquela pergunta com as informações que você possui.\n",
    "\n",
    "Contexto:\n",
    "---\n",
    "{retrieved_context}\n",
    "---\n",
    "\n",
    "Pergunta Step-Back Geral: {step_back_question}\n",
    "Pergunta Específica: {original_query}\n",
    "\n",
    "Resposta Final Detalhada:\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- PASSO 3: Gerando a Resposta Final ---\")\n",
    "\n",
    "final_answer = await call_llm(final_answer_prompt)\n",
    "print(\"Resposta Gerada:\\n\")\n",
    "print(final_answer)\n"
   ],
   "id": "32cd9e458df46f49",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### INICIANDO DEMONSTRAÇÃO ###\n",
      "\n",
      "Pergunta Original Específica:\n",
      "Se eu me inscrever no último dia, 07/11/2025, e pagar a taxa com cartão de crédito, minha inscrição para o curso de Radiologia, que tem requisito de idade, será confirmada imediatamente?\n",
      "\n",
      "--- PASSO 1: Gerando a Pergunta ---\n",
      "Pergunta Gerada: **Pergunta Step‑Back Geral:**\n",
      "\n",
      "*“Quais são os fatores que determinam se a inscrição em um curso, com requisitos específicos (por exemplo, idade) e prazo de inscrição, é confirmada imediatamente após o pagamento?”*\n",
      "\n",
      "--- PASSO 2: Utilizando o contexto já carregado ---\n",
      "Contexto recuperado com sucesso.\n",
      "\n",
      "O contexto recuperado foi:\n",
      "None\n",
      "--- PASSO 3: Gerando a Resposta Final ---\n",
      "Resposta Gerada:\n",
      "\n",
      "Desculpe, mas não há informações suficientes no contexto fornecido para responder a essa pergunta.\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
